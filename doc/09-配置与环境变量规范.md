# EduNexus AI 配置与环境变量规范

## 1. 文档目标
定义 `.env` 配置的统一语义、必填项和环境切换规则，避免“能启动但行为不一致”的问题。

## 2. 配置原则

1. 配置与代码分离，不在代码中硬编码密钥。
2. 每个变量必须有用途说明、默认值与是否必填。
3. `LLM_PROVIDER` 是模型路由总开关。
4. Demo 环境允许本地默认值，但线上必须替换弱密码与占位符。
5. Python 服务必须在 Conda `edunexus-ai` 环境并通过 `uv` 运行。

## 3. 环境变量清单

## 3.1 应用基础

| 变量 | 说明 | 必填 | 示例 |
|---|---|---|---|
| `APP_ENV` | 运行环境 | 是 | `local` |
| `APP_PORT` | 业务后端端口 | 是 | `8080` |
| `AI_SERVICE_PORT` | AI 服务端口 | 是 | `8000` |
| `WEB_PORT` | 前端端口 | 是 | `5173` |

## 3.2 PostgreSQL

| 变量 | 说明 | 必填 | 示例 |
|---|---|---|---|
| `POSTGRES_HOST` | 数据库主机 | 是 | `127.0.0.1` |
| `POSTGRES_PORT` | 端口 | 是 | `5432` |
| `POSTGRES_DB` | 数据库名 | 是 | `edunexus` |
| `POSTGRES_USER` | 用户名 | 是 | `postgres` |
| `POSTGRES_PASSWORD` | 密码 | 是 | `postgres` |
| `DATABASE_URL` | 连接串 | 是 | `postgresql://...` |

## 3.3 Redis

| 变量 | 说明 | 必填 | 示例 |
|---|---|---|---|
| `REDIS_HOST` | Redis 主机 | 是 | `127.0.0.1` |
| `REDIS_PORT` | Redis 端口 | 是 | `6379` |
| `REDIS_URL` | Redis 连接串 | 是 | `redis://127.0.0.1:6379/0` |

## 3.4 Qdrant

| 变量 | 说明 | 必填 | 示例 |
|---|---|---|---|
| `QDRANT_HOST` | Qdrant 主机 | 是 | `127.0.0.1` |
| `QDRANT_PORT` | 端口 | 是 | `6333` |
| `QDRANT_URL` | HTTP 地址 | 是 | `http://127.0.0.1:6333` |
| `QDRANT_API_KEY` | API Key（云端） | 否 | 空 |

## 3.5 MinIO / S3

| 变量 | 说明 | 必填 | 示例 |
|---|---|---|---|
| `S3_ENDPOINT` | 对象存储地址 | 是 | `http://127.0.0.1:9000` |
| `S3_REGION` | 区域 | 是 | `us-east-1` |
| `S3_ACCESS_KEY` | Access Key | 是 | `minioadmin` |
| `S3_SECRET_KEY` | Secret Key | 是 | `minioadmin` |
| `S3_BUCKET` | Bucket 名 | 是 | `edunexus-kb` |
| `S3_FORCE_PATH_STYLE` | 路径风格开关 | 是 | `true` |
| `MINIO_CONSOLE_URL` | MinIO 控制台 | 否 | `http://127.0.0.1:9001` |

## 3.6 鉴权

| 变量 | 说明 | 必填 | 示例 |
|---|---|---|---|
| `JWT_SECRET` | JWT 签名密钥 | 是 | 强随机字符串 |
| `JWT_EXPIRES_IN` | Access Token 过期时间 | 是 | `15m` |
| `REFRESH_TOKEN_EXPIRES_IN` | Refresh Token 过期时间 | 是 | `14d` |
| `AI_SERVICE_TOKEN` | API -> AI 服务间鉴权令牌 | 是 | 强随机字符串 |

## 3.7 LLM 路由

| 变量 | 说明 | 必填 | 示例 |
|---|---|---|---|
| `LLM_PROVIDER` | 模型提供方开关 | 是 | `auto` / `gemini` / `ollama` / `openai` / `deepseek` |
| `OLLAMA_BASE_URL` | 本地 Ollama 地址 | 当 provider=ollama 时必填 | `http://127.0.0.1:11434` |
| `OLLAMA_EMBED_MODEL` | Ollama 嵌入模型 | 当 provider=ollama 时必填 | `qwen3-embedding:0.6b` |
| `OLLAMA_MODEL` | 本地 LLM 模型（快速） | 当 provider=ollama 时必填 | `qwen3:4b` |
| `OLLAMA_RAG_MODEL` | Ollama RAG 主力模型 | 否 | `qwen3:8b` |
| `OLLAMA_COMPLEX_MODEL` | Ollama 深度推理模型 | 否 | `deepseek-r1:8b` |
| `GOOGLE_API_KEY` | Google AI Studio 密钥 | 当 provider=gemini 时必填 | `<secret>` |
| `GEMINI_API_KEY` | Gemini 密钥（兼容命名） | 推荐填 | `<secret>` |
| `GEMINI_MODEL` | Gemini 模型名 | 推荐填 | `gemini-2.0-flash` |
| `OPENAI_API_KEY` | OpenAI 密钥 | 当 provider=openai 时必填 | `<secret>` |
| `DEEPSEEK_API_KEY` | DeepSeek 密钥 | 当 provider=deepseek 时必填 | `<secret>` |
| `DEEPSEEK_MODEL` | DeepSeek 普通模型 | 推荐填 | `deepseek-chat` |
| `DEEPSEEK_COMPLEX_MODEL` | DeepSeek 复杂模型 | 推荐填 | `deepseek-reasoner` |
| `QWEN_API_KEY` | 备用云模型密钥 | 否 | 空 |
| `ANTHROPIC_API_KEY` | 备用云模型密钥 | 否 | 空 |

## 3.8 可观测

| 变量 | 说明 | 必填 | 示例 |
|---|---|---|---|
| `LOG_LEVEL` | 日志级别 | 是 | `INFO` |
| `OTEL_EXPORTER_OTLP_ENDPOINT` | OTEL 上报地址 | 否 | 空 |

## 3.9 Python 运行时隔离（强制）

| 变量 | 说明 | 必填 | 示例 |
|---|---|---|---|
| `PY_ENV_PROVIDER` | Python 环境提供方式 | 是 | `conda`（固定） |
| `PY_ENV_NAME` | Python 专用环境名 | 是 | `edunexus-ai` |
| `PYTHON_BIN` | Python 可执行路径（可选） | 否 | `C:/Users/.../miniforge3/envs/edunexus-ai/python.exe` |
| `PYTHON_RUNNER` | Python 执行器 | 是 | `uv` |
| `UV_PROJECT_ENVIRONMENT` | uv 运行环境目录（可选） | 否 | `.venv` |

强约束：`PY_ENV_NAME` 必须为 `edunexus-ai`，`PYTHON_RUNNER` 必须为 `uv`。

## 4. Provider 切换示例

## 4.1 切到 Gemini（云端）

```env
LLM_PROVIDER=gemini
GOOGLE_API_KEY=<your_google_key>
GEMINI_API_KEY=<your_google_key>
GEMINI_MODEL=gemini-2.0-flash
```

## 4.2 切到 Ollama（本地）

```env
LLM_PROVIDER=ollama
OLLAMA_BASE_URL=http://127.0.0.1:11434
OLLAMA_EMBED_MODEL=qwen3-embedding:0.6b
OLLAMA_MODEL=qwen3:4b
OLLAMA_RAG_MODEL=qwen3:8b
OLLAMA_COMPLEX_MODEL=deepseek-r1:8b
```

## 4.3 自动路由（推荐）

```env
LLM_PROVIDER=auto
OLLAMA_BASE_URL=http://127.0.0.1:11434
OLLAMA_EMBED_MODEL=qwen3-embedding:0.6b
OLLAMA_MODEL=qwen3:4b
OLLAMA_RAG_MODEL=qwen3:8b
OLLAMA_COMPLEX_MODEL=deepseek-r1:8b
DEEPSEEK_API_KEY=<your_deepseek_key>
DEEPSEEK_MODEL=deepseek-chat
DEEPSEEK_COMPLEX_MODEL=deepseek-reasoner
```

自动路由策略：嵌入使用 Ollama qwen3-embedding，简单问答使用 qwen3:4b，RAG 问答使用 qwen3:8b，深度推理使用 deepseek-r1:8b；主路由失败会自动降级到云端 provider。

## 5. 启动顺序

1. 启动基础依赖：PostgreSQL、Redis、Qdrant、MinIO。
2. 启动后端服务（api、ai-service）。
3. 启动前端服务（web）。
4. 访问健康检查与首页。

推荐命令（Windows + Conda）：

```bash
conda run -n edunexus-ai uv sync --project apps/ai-service --python 3.12
conda run -n edunexus-ai uv run --project apps/ai-service --python 3.12 uvicorn ai_service.app:app --host 0.0.0.0 --port 8000
```

说明：请使用 `conda run -n edunexus-ai uv ...`，不要依赖 shell 中的全局 `uv`。

禁止命令（示例）：

```bash
conda activate base && python app/main.py
conda run -n some-other-env uv run --project apps/ai-service uvicorn ai_service.app:app
uv run --project apps/ai-service uvicorn ai_service.app:app
pip install -r requirements.txt && python -m uvicorn ai_service.app:app
```

## 6. 安全注意事项

1. `.env` 不得提交到公开仓库。
2. 任何泄露过的 API Key 必须轮换。
3. `JWT_SECRET` 禁止使用示例值。
4. 生产环境必须使用独立数据库密码与对象存储密钥。
5. CI 与本地启动脚本应在启动前校验 `CONDA_DEFAULT_ENV == edunexus-ai` 且使用 `uv`，不满足时直接退出。

## 7. 最小必填集合（MVP）

- 基础：`APP_ENV`、`APP_PORT`、`AI_SERVICE_PORT`、`WEB_PORT`
- 数据：`DATABASE_URL`、`REDIS_URL`、`QDRANT_URL`
- 存储：`S3_ENDPOINT`、`S3_ACCESS_KEY`、`S3_SECRET_KEY`、`S3_BUCKET`
- 鉴权：`JWT_SECRET`、`JWT_EXPIRES_IN`、`REFRESH_TOKEN_EXPIRES_IN`、`AI_SERVICE_TOKEN`
- 模型：`LLM_PROVIDER` + 对应 provider 的 key/model

---
文档状态：`v1.3.1`（2026-02-27 修正 AI 服务启动模块路径，明确禁止依赖全局 uv）
